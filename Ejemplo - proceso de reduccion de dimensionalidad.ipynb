{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e5a6f9-8abc-48b7-a32c-f92dc1b43066",
   "metadata": {},
   "source": [
    "## Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956f92a-3dfd-47fd-9b71-e6f7facb2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Cargar el archivo de características\n",
    "features_df = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/New features/all channels - all bands/New_alldata_allch_allbands.csv\", header=None)\n",
    "features = features_df.values\n",
    "\n",
    "# Shape of the data:\n",
    "print(\"Dimensions of the data:\", features.shape)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/labels/Labels_All_Data.csv\",\n",
    "                     header=None)\n",
    "labels = df.iloc[:, 0].values\n",
    "\n",
    "# Verificar la forma y la distribución de las etiquetas\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Firts values:\", labels[:10])  # Muestra las primeras 10 etiquetas\n",
    "\n",
    "# Verificar la distribución de las etiquetas\n",
    "label_distribution = Counter(labels)\n",
    "print(\"Labels dsitribution:\", label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec589d-918e-4e79-a62a-a458b97b5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shirt and sweater data:\n",
    "dftrainSS = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/labels/Labels_Shirt_Sweater.csv\",\n",
    "                     header=None)\n",
    "labelsSS = dftrainSS.iloc[:, 0].values\n",
    "\n",
    "# Cargar el archivo de características (suponiendo que las características están en un formato adecuado)\n",
    "featurestrainSS = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/Finals_tests/Final test/All channels - All bands/FinalTest_shirtsweat_allf_allch_bands.csv\", header=None)\n",
    "featuresSS = featurestrainSS.values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "x_div1, x_div2, y_div1, y_div2 = train_test_split(\n",
    "    featuresSS, labelsSS, test_size=0.50, stratify=labelsSS, random_state=42)\n",
    "\n",
    "features = np.vstack((features, x_div1))\n",
    "\n",
    "# Imprimiendo las dimensiones para verificar\n",
    "print(\"Dimensiones de la matriz de características combinada:\", x_train.shape)\n",
    "\n",
    "labels = np.concatenate((labels, y_div1))\n",
    "\n",
    "# Verificación de las dimensiones\n",
    "print(\"Dimensiones de los labels combinados:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135bdad-3b16-4463-859a-b2331164cd05",
   "metadata": {},
   "source": [
    "- Data Division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88c15b-6c5c-4088-93ef-d79bc938a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Verificar la distribución de las clases en los conjuntos de entrenamiento y validación\n",
    "train_counts = Counter(y_train)\n",
    "val_counts = Counter(y_test)\n",
    "\n",
    "print(\"\\nDistribución de clases en el conjunto de entrenamiento:\", train_counts)\n",
    "print(\"Distribución de clases en el conjunto de validación:\", val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22ba2e-b192-4952-bf35-c6c47fa838f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shirt and sweater data:\n",
    "dftrainSS = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/labels/Labels_Shirt_Sweater.csv\",\n",
    "                     header=None)\n",
    "labelsSS = dftrainSS.iloc[:, 0].values\n",
    "\n",
    "# Cargar el archivo de características (suponiendo que las características están en un formato adecuado)\n",
    "featurestrainSS = pd.read_csv(\"/home/andres_marin/Notebooks/Tesis/Finals_tests/Final test/All channels - All bands/FinalTest_shirtsweat_allf_allch_bands.csv\", header=None)\n",
    "featuresSS = featurestrainSS.values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "x_div1, x_div2, y_div1, y_div2 = train_test_split(\n",
    "    featuresSS, labelsSS, test_size=0.50, stratify=labelsSS, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8858125-7328-40aa-b83e-4caa63c5715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Normalizar los datos usando RobustScaler\n",
    "selector = StandardScaler()\n",
    "x_train2 = selector.fit_transform(x_train2)\n",
    "x_train = selector.transform(x_train)\n",
    "x_test = selector.transform(x_test)\n",
    "\n",
    "# Verificar la normalización con RobustScaler\n",
    "print(f'Robust Train Min: {x_train.min()}')\n",
    "print(f'Robust Train Max: {x_train.max()}')\n",
    "print(f'Robust Test Min: {x_test.min()}')\n",
    "print(f'Robust Test Max: {x_test.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112472d-44f3-414a-8d95-597d930a93c2",
   "metadata": {},
   "source": [
    "**To save the normalization scaler:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbb51e-fa7b-461e-8a8b-d4e74834b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Guardar el RobustScaler\n",
    "dump(selector, 'scaler_allbands_allchannels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c6f6c-aa79-4353-8b8d-3adfa8ec2190",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbabde1-cef0-4df8-9032-7b3bcfd9cecd",
   "metadata": {},
   "source": [
    "## KNN: \n",
    "Prepare the model to study the Automatic Feature Selectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd627e-fa5b-4188-8be9-37d9df1fd841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Sugerir el número de vecinos (sólo números impares)\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31, step=2)\n",
    "\n",
    "    # Sugerir la métrica de distancia\n",
    "    metric = trial.suggest_categorical('metric',['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming', 'canberra', 'seuclidean'])\n",
    "\n",
    "    # Configurar parámetros adicionales si se selecciona Minkowski o SEuclidean\n",
    "    if metric == 'minkowski':\n",
    "        p = trial.suggest_float('p', 1, 4)\n",
    "        metric_params = {'p': p}\n",
    "    elif metric == 'seuclidean':\n",
    "        # Calcular el vector de varianzas de los datos de entrenamiento para seuclidean\n",
    "        V = np.var(x_train, axis=0)\n",
    "        metric_params = {'V': V}\n",
    "    else:\n",
    "        metric_params = None\n",
    "\n",
    "    # Crear el clasificador k-NN con los parámetros sugeridos\n",
    "    classifier = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric, metric_params=metric_params)\n",
    "\n",
    "    # Entrenar el clasificador en el conjunto de entrenamiento\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predecir el conjunto de prueba\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluar el clasificador usando la precisión en el conjunto de prueba\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Crear un estudio de Optuna y encontrar los mejores parámetros\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Imprimir los mejores parámetros\n",
    "print(\"Mejores parámetros: \", study.best_params)\n",
    "print(\"Mejor precisión obtenida: \", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29396813-bc0e-4f9e-b960-7977b355d51b",
   "metadata": {},
   "source": [
    "## SVM: \n",
    "Prepare the model to study the Automatic Feature Selectors: **(RFE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd08dc-137b-4d5d-afa6-54ff46586b31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    C = trial.suggest_float('C', 0.01, 4, log=True)\n",
    "    \n",
    "    # Crear el objeto del clasificador SVC con los hiperparámetros sugeridos\n",
    "    classifier_obj = SVC(kernel='linear', C=C, random_state=42)\n",
    "\n",
    "    # Entrenar el modelo con el conjunto de entrenamiento cargado\n",
    "    classifier_obj.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo con el conjunto de prueba\n",
    "    y_pred = classifier_obj.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Crear y optimizar el estudio\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "print('Mejores parámetros:', study.best_params)\n",
    "print('Mejor resultado de precisión:', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44bdf4-ae8e-45e8-be1b-ffb3205224ef",
   "metadata": {},
   "source": [
    "## LDA: \n",
    "Prepare the model to study the Automatic Feature Selectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281ed51-9d27-4d58-95b6-3680b534e583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que x_train, y_train, x_test, y_test están definidos\n",
    "\n",
    "def objective(trial):\n",
    "    # Sugerencias para los hiperparámetros\n",
    "    solver = trial.suggest_categorical('solver', ['svd', 'lsqr', 'eigen'])\n",
    "    shrinkage = None\n",
    "    if solver in ['lsqr', 'eigen']:\n",
    "        shrinkage = trial.suggest_categorical('shrinkage', ['auto', None])\n",
    "        \n",
    "    # Los priors pueden ser None o un arreglo que sume 1 y represente la probabilidad a priori de cada clase\n",
    "    num_classes = np.unique(y_train).size\n",
    "    if trial.suggest_categorical('optimize_priors', [True, False]):\n",
    "        priors = np.array([trial.suggest_float(f'prior_{i}', 0.01, 1) for i in range(num_classes)])\n",
    "        priors = priors / np.sum(priors)  # Normalizar para que sumen 1\n",
    "    else:\n",
    "        priors = None\n",
    "\n",
    "    # Crear el objeto del clasificador LDA con los hiperparámetros sugeridos\n",
    "    classifier_obj = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "\n",
    "    # Entrenar el modelo con el conjunto de entrenamiento\n",
    "    classifier_obj.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo con el conjunto de prueba\n",
    "    y_pred = classifier_obj.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Crear un estudio de Optuna y optimizar\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Mejores parámetros:', study.best_params)\n",
    "print('Mejor resultado de precisión:', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75e68b-6c75-4ac9-917b-da7a6220fb58",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cfeac-361a-4851-8822-b239ca8ad43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # Crear el objeto del clasificador RandomForest con los hiperparámetros sugeridos\n",
    "    classifier_obj = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo con el conjunto de entrenamiento\n",
    "    classifier_obj.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo con el conjunto de prueba\n",
    "    y_pred = classifier_obj.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Crear y optimizar el estudio\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Mejores parámetros:', study.best_params)\n",
    "print('Mejor resultado de precisión:', study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761cc2c-25f3-4291-85a8-38a8b7fe6d32",
   "metadata": {},
   "source": [
    "# 1. Feature elmination:\n",
    "1. Recursive Feature Elimination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0536f4-7972-464b-83af-5cfd7559bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros obtenidos de Optuna\n",
    "solver = 'eigen'\n",
    "shrinkage = 'auto'\n",
    "priors = [0.5035153587365824, 0.32907437446065674]\n",
    "\n",
    "# Normalizar priors para que sumen 1\n",
    "priors = np.array(priors)\n",
    "priors = priors / np.sum(priors)\n",
    "\n",
    "# KNN:\n",
    "V = np.var(x_train, axis=0)\n",
    "metric_params = {'V': V}\n",
    "\n",
    "# Models:\n",
    "lda = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "svm = SVC(kernel='linear', C= 0.10863871483648994, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=779, max_depth=39, min_samples_split=9, min_samples_leaf=8, max_features='sqrt', random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=13, metric= 'chebyshev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8b04a-87ac-4c9a-a2e2-ca1fa7bf5531",
   "metadata": {},
   "source": [
    "**RFE for the SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d1f37-3a88-4920-868e-6b3aade5ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectorSVM = RFECV(estimator=svm, step=1, cv=5, scoring='accuracy')\n",
    "selectorSVM.fit(x_train, y_train)\n",
    "\n",
    "# Evaluación del modelo con las características seleccionadas\n",
    "print(\"Número óptimo de características: %d\" % selectorSVM.n_features_)\n",
    "print(\"Características seleccionadas: %s\" % selectorSVM.support_)\n",
    "\n",
    "X_train_selectedSVM = selectorSVM.transform(x_train)\n",
    "X_test_selectedSVM = selectorSVM.transform(x_test)\n",
    "svm.fit(X_train_selectedSVM, y_train)\n",
    "y_pred = svm.predict(X_test_selectedSVM)\n",
    "print(\"Precisión después de la selección de características: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96df4e-ba08-4cbd-961b-26ef2574190d",
   "metadata": {},
   "source": [
    "**RFE for the LDA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f807b45-e286-48b5-86e8-90076b6f3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar RFECV para seleccionar características para el LDA:\n",
    "selectorLDA = RFECV(estimator=lda, step=1, cv=5, scoring='accuracy')\n",
    "selectorLDA.fit(x_train, y_train)\n",
    "\n",
    "# Evaluación del modelo con las características seleccionadas\n",
    "print(\"Número óptimo de características: %d\" % selectorLDA.n_features_)\n",
    "print(\"Características seleccionadas: %s\" % selectorLDA.support_)\n",
    "\n",
    "X_train_selectedLDA = selectorLDA.transform(x_train)\n",
    "X_test_selectedLDA = selectorLDA.transform(x_test)\n",
    "lda.fit(X_train_selectedLDA, y_train)\n",
    "y_pred = lda.predict(X_test_selectedLDA)\n",
    "print(\"Precisión después de la selección de características: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a21df-4f17-4c1e-844d-9a856cf81b2b",
   "metadata": {},
   "source": [
    "**RFE for the Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cf3c4-20c4-4ee5-94f1-8c528068cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar RFECV para seleccionar características para el LDA:\n",
    "selectorRF = RFECV(estimator=rf, step=1, cv=5, scoring='accuracy')\n",
    "selectorRF.fit(x_train, y_train)\n",
    "\n",
    "# Evaluación del modelo con las características seleccionadas\n",
    "print(\"Número óptimo de características: %d\" % selectorRF.n_features_)\n",
    "print(\"Características seleccionadas: %s\" % selectorRF.support_)\n",
    "\n",
    "X_train_selectedRF = selectorRF.transform(x_train)\n",
    "X_test_selectedRF = selectorRF.transform(x_test)\n",
    "rf.fit(X_train_selectedRF, y_train)\n",
    "y_pred = rf.predict(X_test_selectedRF)\n",
    "print(\"Precisión después de la selección de características: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63732ee6-1789-4531-98a8-5795e391a2ae",
   "metadata": {},
   "source": [
    "*Save Selectors:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc937ba7-6908-4c2b-bfa8-321f5df66584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Guardar el selector en un archivo\n",
    "dump(selectorSVM, 'selector_rfecv_svm.joblib')\n",
    "dump(selectorLDA, 'selector_rfecv_lda.joblib')\n",
    "dump(selectorRF, 'selector_rfecv_rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6432e-2124-49d4-a6b7-01f96fab86f3",
   "metadata": {},
   "source": [
    "# 2. From the Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1492c-ad88-4c40-aec3-2468ca0dcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros obtenidos de Optuna\n",
    "solver = 'eigen'\n",
    "shrinkage = 'auto'\n",
    "priors = [0.5035153587365824, 0.32907437446065674]\n",
    "\n",
    "# Normalizar priors para que sumen 1\n",
    "priors = np.array(priors)\n",
    "priors = priors / np.sum(priors)\n",
    "\n",
    "# KNN:\n",
    "V = np.var(x_train, axis=0)\n",
    "metric_params = {'V': V}\n",
    "\n",
    "# Models:\n",
    "lda = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "svm = SVC(kernel='linear', C= 0.10863871483648994, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=779, max_depth=39, min_samples_split=9, min_samples_leaf=8, max_features='sqrt', random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=13, metric= 'chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b2f6c-5aab-4c2e-9dee-bb23bdb6f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e4c20-8ef8-4436-9bd4-31a4dfc44dc3",
   "metadata": {},
   "source": [
    "*Using the information manually:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c931a-079e-4497-a124-7eb7b61efb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_mean = SelectFromModel(rf, threshold='mean')\n",
    "X_train_mean = sfm_mean.fit_transform(x_train, y_train)\n",
    "\n",
    "# Umbral como la mediana de las importancias\n",
    "sfm_median = SelectFromModel(rf, threshold='median')\n",
    "X_train_median = sfm_median.fit_transform(x_train, y_train)\n",
    "\n",
    "# Umbral personalizado, por ejemplo, 1.5 veces la media de las importancias\n",
    "mean_importance = rf.feature_importances_.mean()\n",
    "sfm_custom = SelectFromModel(rf, threshold=1.5 * mean_importance)\n",
    "X_train_custom = sfm_custom.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcd169-2207-4204-9f88-f0f9a8c0ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Definir los umbrales a evaluar\n",
    "thresholds = ['mean', 'median', 0.01]\n",
    "results = []\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Ciclo para evaluar cada umbral\n",
    "for threshold in thresholds:\n",
    "    sfm = SelectFromModel(rf, threshold=threshold)\n",
    "    X_train_transformed = sfm.fit_transform(x_train, y_train)\n",
    "    scores = cross_val_score(rf, X_train_transformed, y_train, cv=cv, scoring='accuracy')\n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'mean_accuracy': np.mean(scores),\n",
    "        'std_dev': np.std(scores),\n",
    "        'num_features': X_train_transformed.shape[1]\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "for result in results:\n",
    "    print(f\"Umbral: {result['threshold']}, Precisión media: {result['mean_accuracy']:.4f}, Desv. Est.: {result['std_dev']:.4f}, Núm. Características: {result['num_features']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fae634-c22b-41e7-97a8-10a0b7543720",
   "metadata": {},
   "source": [
    "**Saving the Selector Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfb80b-139c-450d-87ce-8940171acbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "sfm = SelectFromModel(rf, threshold='median')\n",
    "sfm.fit(x_train, y_train)\n",
    "\n",
    "# Save the model:\n",
    "from joblib import dump\n",
    "dump(sfm, 'sfmMean.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256dfbae-d9d3-42ca-b722-3ce6f61ddde4",
   "metadata": {},
   "source": [
    "**Testing the models with the selector:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f34b7-86c3-4085-8c3d-a15c5214a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "sfm=load('/home/andres_marin/Notebooks/Tesis/Finals_tests/Selectors/2. Random Forest/sfm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ea7cf-71b7-4a4e-86a9-96bad419aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros obtenidos de Optuna\n",
    "solver = 'eigen'\n",
    "shrinkage = 'auto'\n",
    "priors = [0.9954204041462262, 0.5897282542157889]\n",
    "\n",
    "# Normalizar priors para que sumen 1\n",
    "priors = np.array(priors)\n",
    "priors = priors / np.sum(priors)\n",
    "\n",
    "# Models:\n",
    "lda = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "svm = SVC(kernel='linear', C=0.03145231545300702, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=792, max_depth=2, min_samples_split=5, min_samples_leaf=8, max_features='sqrt', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc7ae2-ae08-4795-93cf-90d057ee182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the new features:\n",
    "x_trainRandomForest = sfm.transform(x_train)\n",
    "x_testRandomForest = sfm.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf9d45-d4c9-4c26-9556-cbb18faf8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models:\n",
    "svm.fit(x_trainRandomForest, y_train)\n",
    "lda.fit(x_trainRandomForest, y_train)\n",
    "rf.fit(x_trainRandomForest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0036b-e8db-444f-a742-d3003f85b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models:\n",
    "\n",
    "# SVM:\n",
    "y_pred = svm.predict(x_testRandomForest)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with SVM: {accuracy:.4f}\")\n",
    "\n",
    "# LDA:\n",
    "y_pred = lda.predict(x_testRandomForest)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with LDA: {accuracy:.4f}\")\n",
    "\n",
    "# Random Forest:\n",
    "y_pred = rf.predict(x_testRandomForest)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Random Forest: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a005ad-d3a2-4772-bd88-52649468018b",
   "metadata": {},
   "source": [
    "# 3. Sequential Feature Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d184588-dc5b-418a-ad5d-a2caaebfdd90",
   "metadata": {},
   "source": [
    "**Load the models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d7d54-0ffd-4a43-a38c-8242ecfe61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros obtenidos de Optuna\n",
    "solver = 'eigen'\n",
    "shrinkage = 'auto'\n",
    "priors = [0.9954204041462262, 0.5897282542157889]\n",
    "\n",
    "# Normalizar priors para que sumen 1\n",
    "priors = np.array(priors)\n",
    "priors = priors / np.sum(priors)\n",
    "\n",
    "# KNN:\n",
    "V = np.var(x_train, axis=0)\n",
    "metric_params = {'V': V}\n",
    "\n",
    "# Models:\n",
    "lda = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "svm = SVC(kernel='linear', C=0.03145231545300702, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=792, max_depth=2, min_samples_split=5, min_samples_leaf=8, max_features='sqrt', random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=15, metric= 'seuclidean', metric_params=metric_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb47335-4d5e-445d-92fa-67d43ae8e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Configurar SFS\n",
    "sfsLDA = SFS(lda,\n",
    "          k_features='best',  # Selecciona el número de características que resulte en el mejor rendimiento\n",
    "          forward=True,  # True para selección hacia adelante, False para selección hacia atrás\n",
    "          floating=False,  # 'Floating' puede eliminar o añadir en cada paso dependiendo del criterio\n",
    "          scoring='accuracy',  # Métrica de rendimiento\n",
    "          cv=5)  # Validación cruzada\n",
    "sfsLDA.fit(x_train, y_train)\n",
    "\n",
    "# Resultados de la selección de características\n",
    "print('Número de características seleccionadas:', len(sfsLDA.k_feature_names_))\n",
    "print('Mejores características:', sfsLDA.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb8143-5360-47f0-b9c5-e8864ea4a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(sfsLDA, 'sfsLDA.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750dba1-f67f-45a3-9070-d4127c42726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar SFS\n",
    "sfsSVM = SFS(svm,\n",
    "          k_features='best',  # Selecciona el número de características que resulte en el mejor rendimiento\n",
    "          forward=True,  # True para selección hacia adelante, False para selección hacia atrás\n",
    "          floating=False,  # 'Floating' puede eliminar o añadir en cada paso dependiendo del criterio\n",
    "          scoring='accuracy',  # Métrica de rendimiento\n",
    "          cv=5)  # Validación cruzada\n",
    "sfsSVM.fit(x_train, y_train)\n",
    "\n",
    "# Resultados de la selección de características\n",
    "print('Número de características seleccionadas:', len(sfsSVM.k_feature_names_))\n",
    "print('Mejores características:', sfsSVM.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04264cb-b135-4d72-ac5b-b36700b1e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(sfsSVM, 'sfsLDA.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bc5e1-6901-46a5-822e-3c094bf2d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar SFS\n",
    "sfsKNN = SFS(knn,\n",
    "          k_features='best',  # Selecciona el número de características que resulte en el mejor rendimiento\n",
    "          forward=True,  # True para selección hacia adelante, False para selección hacia atrás\n",
    "          floating=False,  # 'Floating' puede eliminar o añadir en cada paso dependiendo del criterio\n",
    "          scoring='accuracy',  # Métrica de rendimiento\n",
    "          cv=5)  # Validación cruzada\n",
    "sfsKNN.fit(x_train, y_train)\n",
    "\n",
    "# Resultados de la selección de características\n",
    "print('Número de características seleccionadas:', len(sfsKNN.k_feature_names_))\n",
    "print('Mejores características:', sfsKNN.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785eed8-daea-41c3-9371-741f11a23d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(sfsKNN, 'sfsLDA.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a9c7b-9b18-4541-b23a-941ff9ae2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar SFS\n",
    "sfsRF = SFS(rf,\n",
    "          k_features='best',  # Selecciona el número de características que resulte en el mejor rendimiento\n",
    "          forward=True,  # True para selección hacia adelante, False para selección hacia atrás\n",
    "          floating=False,  # 'Floating' puede eliminar o añadir en cada paso dependiendo del criterio\n",
    "          scoring='accuracy',  # Métrica de rendimiento\n",
    "          cv=5)  # Validación cruzada\n",
    "sfsRF.fit(x_train, y_train)\n",
    "\n",
    "# Resultados de la selección de características\n",
    "print('Número de características seleccionadas:', len(sfsRF.k_feature_names_))\n",
    "print('Mejores características:', sfsRF.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4bdab-4d01-41b9-bece-faa4b4907e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(sfsRF, 'sfsLDA.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe0159d-94d6-483a-bbea-ea14d60f83a2",
   "metadata": {},
   "source": [
    "# 4. L1-based feature selection (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfbc42-b69b-4c2f-85e9-a163a0d2db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lasso = Lasso(alpha=0.0007)  # Ajusta el valor de alpha según necesidad\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "X_train_selected = model.transform(x_train)\n",
    "X_test_selected = model.transform(x_test)\n",
    "\n",
    "# Obtener la máscara de las características seleccionadas\n",
    "selected_features = model.get_support()\n",
    "# Contar las características seleccionadas\n",
    "number_of_selected_features = selected_features.sum()\n",
    "\n",
    "print(\"Número de características seleccionadas:\", number_of_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf48fe-c76e-427f-b18c-d7a0280bd67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "from joblib import dump\n",
    "dump(model, 'L1_Selector.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa634ff-2986-4c45-aaa5-ffc4efaec179",
   "metadata": {},
   "source": [
    "# 5. Mutal Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff535e7d-9612-439d-b0e1-d5227babc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros obtenidos de Optuna\n",
    "solver = 'eigen'\n",
    "shrinkage = 'auto'\n",
    "priors = [0.5035153587365824, 0.32907437446065674]\n",
    "\n",
    "# Normalizar priors para que sumen 1\n",
    "priors = np.array(priors)\n",
    "priors = priors / np.sum(priors)\n",
    "\n",
    "# KNN:\n",
    "V = np.var(x_train, axis=0)\n",
    "metric_params = {'V': V}\n",
    "\n",
    "# Models:\n",
    "lda = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage, priors=priors)\n",
    "svm = SVC(kernel='linear', C= 0.10863871483648994, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=779, max_depth=39, min_samples_split=9, min_samples_leaf=8, max_features='sqrt', random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=13, metric= 'chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c877c6-e13d-4dbf-9911-79d0c8df9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para guardar los puntajes promedio de validación cruzada\n",
    "mean_scores = []\n",
    "\n",
    "# Rango de 'k' a probar\n",
    "k_values = range(1, 280)  # Puedes ajustar este rango según la cantidad de características iniciales\n",
    "\n",
    "# Inicializar la variable para el selector óptimo\n",
    "best_selector = None\n",
    "\n",
    "for k in k_values:\n",
    "    # Selección de las 'k' mejores características basada en información mutua\n",
    "    selector = SelectKBest(mutual_info_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(x_train, y_train)\n",
    "    \n",
    "    # Crear y evaluar el clasificador usando validación cruzada\n",
    "    clf = rf\n",
    "    scores = cross_val_score(clf, X_train_selected, y_train, cv=5)\n",
    "    mean_scores.append(np.mean(scores))\n",
    "    \n",
    "    # Guardar el selector óptimo\n",
    "    if np.mean(scores) == max(mean_scores):\n",
    "        best_selector = selector\n",
    "\n",
    "# Encontrar el valor de 'k' que maximizó el puntaje de validación cruzada\n",
    "optimal_k = k_values[np.argmax(mean_scores)]\n",
    "print(\"Óptimo número de características:\", optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be3537-4e42-4d53-8691-1878a0614d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "from joblib import dump\n",
    "dump(best_selector, 'MS_rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2e881-3a05-4462-a52f-6b3ae848b495",
   "metadata": {},
   "source": [
    "# 6. PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da63db-18e6-4545-8cdd-3a440d7c2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Inicializar PCA para que retenga el 95% de la varianza\n",
    "pca = PCA(n_components=0.99)\n",
    "\n",
    "# Ajustar PCA al dataset escalado\n",
    "X_pca = pca.fit_transform(x_train)\n",
    "\n",
    "# Mostrar el nuevo número de componentes\n",
    "print(\"Número de componentes seleccionados:\", pca.n_components_)\n",
    "print(\"Varianza explicada por cada componente:\", pca.explained_variance_ratio_)\n",
    "print(\"Varianza total explicada:\", sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7fda4-fa47-4a12-9580-b2d55d217683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "from joblib import dump\n",
    "dump(pca, 'pca.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
